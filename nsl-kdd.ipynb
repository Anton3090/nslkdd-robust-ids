{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3f89bf2",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-21T20:12:16.079547Z",
     "iopub.status.busy": "2025-05-21T20:12:16.079317Z",
     "iopub.status.idle": "2025-05-21T20:12:17.684120Z",
     "shell.execute_reply": "2025-05-21T20:12:17.683323Z"
    },
    "papermill": {
     "duration": 1.610514,
     "end_time": "2025-05-21T20:12:17.685342",
     "exception": false,
     "start_time": "2025-05-21T20:12:16.074828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/KDDTest+.arff\n",
      "/kaggle/input/KDDTest-21.arff\n",
      "/kaggle/input/KDDTest1.jpg\n",
      "/kaggle/input/KDDTrain+.txt\n",
      "/kaggle/input/KDDTrain+_20Percent.txt\n",
      "/kaggle/input/KDDTest-21.txt\n",
      "/kaggle/input/KDDTest+.txt\n",
      "/kaggle/input/KDDTrain+.arff\n",
      "/kaggle/input/index.html\n",
      "/kaggle/input/KDDTrain+_20Percent.arff\n",
      "/kaggle/input/KDDTrain1.jpg\n",
      "/kaggle/input/nsl-kdd/KDDTest+.arff\n",
      "/kaggle/input/nsl-kdd/KDDTest-21.arff\n",
      "/kaggle/input/nsl-kdd/KDDTest1.jpg\n",
      "/kaggle/input/nsl-kdd/KDDTrain+.txt\n",
      "/kaggle/input/nsl-kdd/KDDTrain+_20Percent.txt\n",
      "/kaggle/input/nsl-kdd/KDDTest-21.txt\n",
      "/kaggle/input/nsl-kdd/KDDTest+.txt\n",
      "/kaggle/input/nsl-kdd/KDDTrain+.arff\n",
      "/kaggle/input/nsl-kdd/index.html\n",
      "/kaggle/input/nsl-kdd/KDDTrain+_20Percent.arff\n",
      "/kaggle/input/nsl-kdd/KDDTrain1.jpg\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e802989",
   "metadata": {
    "papermill": {
     "duration": 0.002616,
     "end_time": "2025-05-21T20:12:17.691043",
     "exception": false,
     "start_time": "2025-05-21T20:12:17.688427",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Dataset Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75b5c36b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T20:12:17.697273Z",
     "iopub.status.busy": "2025-05-21T20:12:17.696968Z",
     "iopub.status.idle": "2025-05-21T20:12:20.068643Z",
     "shell.execute_reply": "2025-05-21T20:12:20.068034Z"
    },
    "papermill": {
     "duration": 2.376565,
     "end_time": "2025-05-21T20:12:20.070251",
     "exception": false,
     "start_time": "2025-05-21T20:12:17.693686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /kaggle/input/\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Download and load the dataset\n",
    "path = kagglehub.dataset_download(\"hassan06/nslkdd\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# Load train and test datasets\n",
    "train_df = pd.read_csv(f\"{path}/KDDTrain+.txt\", header=None)\n",
    "test_df = pd.read_csv(f\"{path}/KDDTest+.txt\", header=None)\n",
    "\n",
    "# NSL-KDD has 41 features + 1 label column\n",
    "columns = [\n",
    "    'duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes',\n",
    "    'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in',\n",
    "    'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations',\n",
    "    'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login',\n",
    "    'is_guest_login', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate',\n",
    "    'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate',\n",
    "    'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count',\n",
    "    'dst_host_same_srv_rate', 'dst_host_diff_srv_rate',\n",
    "    'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate',\n",
    "    'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n",
    "    'dst_host_srv_rerror_rate', 'label', 'difficulty_level'  # added last column\n",
    "]\n",
    "\n",
    "train_df.columns = test_df.columns = columns\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d602b1",
   "metadata": {
    "papermill": {
     "duration": 0.002678,
     "end_time": "2025-05-21T20:12:20.076055",
     "exception": false,
     "start_time": "2025-05-21T20:12:20.073377",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10bfce0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T20:12:20.082350Z",
     "iopub.status.busy": "2025-05-21T20:12:20.082109Z",
     "iopub.status.idle": "2025-05-21T20:12:20.360459Z",
     "shell.execute_reply": "2025-05-21T20:12:20.359622Z"
    },
    "papermill": {
     "duration": 0.283127,
     "end_time": "2025-05-21T20:12:20.361904",
     "exception": false,
     "start_time": "2025-05-21T20:12:20.078777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Binary classification: normal vs attack\n",
    "train_df['label'] = train_df['label'].apply(lambda x: 'normal' if x == 'normal' else 'attack')\n",
    "test_df['label'] = test_df['label'].apply(lambda x: 'normal' if x == 'normal' else 'attack')\n",
    "\n",
    "# Encode categorical features\n",
    "cat_cols = ['protocol_type', 'service', 'flag']\n",
    "encoder = LabelEncoder()\n",
    "for col in cat_cols:\n",
    "    train_df[col] = encoder.fit_transform(train_df[col])\n",
    "    test_df[col] = encoder.transform(test_df[col])\n",
    "\n",
    "# Separate features and labels\n",
    "X_train = train_df.drop('label', axis=1)\n",
    "y_train = LabelEncoder().fit_transform(train_df['label'])\n",
    "\n",
    "X_test = test_df.drop('label', axis=1)\n",
    "y_test = LabelEncoder().fit_transform(test_df['label'])\n",
    "\n",
    "# Normalize\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de76e335",
   "metadata": {
    "papermill": {
     "duration": 0.002637,
     "end_time": "2025-05-21T20:12:20.367567",
     "exception": false,
     "start_time": "2025-05-21T20:12:20.364930",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Build & Train Deep Learning Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e960fcc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T20:12:20.373969Z",
     "iopub.status.busy": "2025-05-21T20:12:20.373706Z",
     "iopub.status.idle": "2025-05-21T20:12:53.098719Z",
     "shell.execute_reply": "2025-05-21T20:12:53.097589Z"
    },
    "papermill": {
     "duration": 32.72968,
     "end_time": "2025-05-21T20:12:53.100129",
     "exception": false,
     "start_time": "2025-05-21T20:12:20.370449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Loss: 0.0227\n",
      "Epoch 2 - Loss: 0.0005\n",
      "Epoch 3 - Loss: 0.0000\n",
      "Epoch 4 - Loss: 0.0031\n",
      "Epoch 5 - Loss: 0.0067\n",
      "Epoch 6 - Loss: 0.0042\n",
      "Epoch 7 - Loss: 0.0007\n",
      "Epoch 8 - Loss: 0.0256\n",
      "Epoch 9 - Loss: 0.0012\n",
      "Epoch 10 - Loss: 0.0001\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=128, shuffle=True)\n",
    "\n",
    "# Define model\n",
    "class IDSModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(IDSModel, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 2)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "model = IDSModel(X_train.shape[1])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training\n",
    "for epoch in range(10):\n",
    "    for xb, yb in train_loader:\n",
    "        out = model(xb)\n",
    "        loss = criterion(out, yb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1} - Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59076585",
   "metadata": {
    "papermill": {
     "duration": 0.003164,
     "end_time": "2025-05-21T20:12:53.106800",
     "exception": false,
     "start_time": "2025-05-21T20:12:53.103636",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "171922f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T20:12:53.114126Z",
     "iopub.status.busy": "2025-05-21T20:12:53.113755Z",
     "iopub.status.idle": "2025-05-21T20:12:53.133683Z",
     "shell.execute_reply": "2025-05-21T20:12:53.133020Z"
    },
    "papermill": {
     "duration": 0.024934,
     "end_time": "2025-05-21T20:12:53.134894",
     "exception": false,
     "start_time": "2025-05-21T20:12:53.109960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8725603222846985\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    preds = torch.argmax(model(X_test_tensor), dim=1)\n",
    "    acc = (preds == y_test_tensor).float().mean()\n",
    "print(\"Test Accuracy:\", acc.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c764dc",
   "metadata": {
    "papermill": {
     "duration": 0.002851,
     "end_time": "2025-05-21T20:12:53.140846",
     "exception": false,
     "start_time": "2025-05-21T20:12:53.137995",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Real-Time Packet Detection with Scapy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fba079d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T20:12:53.147659Z",
     "iopub.status.busy": "2025-05-21T20:12:53.147460Z",
     "iopub.status.idle": "2025-05-21T20:12:53.151901Z",
     "shell.execute_reply": "2025-05-21T20:12:53.151232Z"
    },
    "papermill": {
     "duration": 0.009014,
     "end_time": "2025-05-21T20:12:53.152915",
     "exception": false,
     "start_time": "2025-05-21T20:12:53.143901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save(model.state_dict(), 'ids_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2ae65e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T20:12:53.159802Z",
     "iopub.status.busy": "2025-05-21T20:12:53.159603Z",
     "iopub.status.idle": "2025-05-21T20:14:10.950112Z",
     "shell.execute_reply": "2025-05-21T20:14:10.949340Z"
    },
    "papermill": {
     "duration": 77.795497,
     "end_time": "2025-05-21T20:14:10.951533",
     "exception": false,
     "start_time": "2025-05-21T20:12:53.156036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scapy\r\n",
      "  Downloading scapy-2.6.1-py3-none-any.whl.metadata (5.6 kB)\r\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\r\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.5.0)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\r\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\r\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\r\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\r\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy) (2025.1.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy) (2022.1.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy) (2.4.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2022.1.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy) (1.3.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy) (2024.2.0)\r\n",
      "Downloading scapy-2.6.1-py3-none-any.whl (2.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: scapy, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\r\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\r\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\r\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\r\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.10.19\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.10.19:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.4.0.6\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.4.0.6:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.9.0.13\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.9.0.13:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\r\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 scapy-2.6.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install scapy torch numpy joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31b62834",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T20:14:10.996435Z",
     "iopub.status.busy": "2025-05-21T20:14:10.995850Z",
     "iopub.status.idle": "2025-05-21T20:14:11.061500Z",
     "shell.execute_reply": "2025-05-21T20:14:11.060756Z"
    },
    "papermill": {
     "duration": 0.089115,
     "end_time": "2025-05-21T20:14:11.062715",
     "exception": false,
     "start_time": "2025-05-21T20:14:10.973600",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.save']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "# Example: Fit scaler to your training features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)  # X_train should be your training features (without labels)\n",
    "\n",
    "# Save to a file\n",
    "joblib.dump(scaler, \"scaler.save\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bcd1156",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T20:14:11.110855Z",
     "iopub.status.busy": "2025-05-21T20:14:11.110625Z",
     "iopub.status.idle": "2025-05-21T20:14:21.963761Z",
     "shell.execute_reply": "2025-05-21T20:14:21.962941Z"
    },
    "papermill": {
     "duration": 10.878741,
     "end_time": "2025-05-21T20:14:21.964934",
     "exception": false,
     "start_time": "2025-05-21T20:14:11.086193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sniffing packets for 10 seconds...\n",
      "[2025-05-21 20:14:15.888260] Packet classified as: attack\n",
      "[2025-05-21 20:14:15.889633] Packet classified as: attack\n",
      "[2025-05-21 20:14:15.890403] Packet classified as: attack\n",
      "[2025-05-21 20:14:15.891126] Packet classified as: attack\n",
      "Sniffing finished.\n"
     ]
    }
   ],
   "source": [
    "from scapy.all import sniff, IP, TCP, UDP\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the model\n",
    "class IDSModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(IDSModel, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 2)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "# Load model and scaler\n",
    "model = IDSModel(input_dim=42)\n",
    "model.load_state_dict(torch.load(\"ids_model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "scaler = joblib.load(\"scaler.save\")\n",
    "\n",
    "# Feature extraction function\n",
    "def extract_features(pkt):\n",
    "    try:\n",
    "        length = len(pkt)\n",
    "        ttl = pkt[IP].ttl if IP in pkt else 0\n",
    "        dport = pkt[TCP].dport if TCP in pkt else (pkt[UDP].dport if UDP in pkt else 0)\n",
    "        features = [length, ttl, dport]\n",
    "        features += [0] * (42 - len(features))  # Pad to 42 features\n",
    "        return np.array(features).reshape(1, -1)\n",
    "    except:\n",
    "        return np.zeros((1, 42))  # Return dummy on failure\n",
    "\n",
    "# Classify and log packet\n",
    "def classify_packet(pkt):\n",
    "    features = extract_features(pkt)\n",
    "    scaled = scaler.transform(features)\n",
    "    tensor = torch.tensor(scaled, dtype=torch.float32)\n",
    "    output = model(tensor)\n",
    "    pred = torch.argmax(output).item()\n",
    "    label = \"attack\" if pred == 1 else \"normal\"\n",
    "\n",
    "    print(f\"[{datetime.now()}] Packet classified as: {label}\")\n",
    "    with open(\"log.txt\", \"a\") as f:\n",
    "        f.write(f\"{datetime.now()} | {pkt.summary()} | Result: {label}\\n\")\n",
    "\n",
    "# Start sniffing for 10 seconds\n",
    "print(\"Sniffing packets for 10 seconds...\")\n",
    "sniff(prn=classify_packet, timeout=10, store=0)\n",
    "print(\"Sniffing finished.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5128ad",
   "metadata": {
    "papermill": {
     "duration": 0.022036,
     "end_time": "2025-05-21T20:14:22.009394",
     "exception": false,
     "start_time": "2025-05-21T20:14:21.987358",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Logging to a Text File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e7f7668",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T20:14:22.054680Z",
     "iopub.status.busy": "2025-05-21T20:14:22.054093Z",
     "iopub.status.idle": "2025-05-21T20:14:22.058162Z",
     "shell.execute_reply": "2025-05-21T20:14:22.057622Z"
    },
    "papermill": {
     "duration": 0.027879,
     "end_time": "2025-05-21T20:14:22.059081",
     "exception": false,
     "start_time": "2025-05-21T20:14:22.031202",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def log_packet(pkt, result):\n",
    "    with open(\"log.txt\", \"a\") as f:\n",
    "        f.write(f\"{datetime.datetime.now()} | {pkt.summary()} | Result: {result}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3696fc07",
   "metadata": {
    "papermill": {
     "duration": 0.021655,
     "end_time": "2025-05-21T20:14:22.102262",
     "exception": false,
     "start_time": "2025-05-21T20:14:22.080607",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Secure Model with Adversarial Robustness Toolbox (ART)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee82bcb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T20:14:22.190687Z",
     "iopub.status.busy": "2025-05-21T20:14:22.190301Z",
     "iopub.status.idle": "2025-05-21T20:14:30.870587Z",
     "shell.execute_reply": "2025-05-21T20:14:30.869644Z"
    },
    "papermill": {
     "duration": 8.703755,
     "end_time": "2025-05-21T20:14:30.871830",
     "exception": false,
     "start_time": "2025-05-21T20:14:22.168075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting adversarial-robustness-toolbox\r\n",
      "  Downloading adversarial_robustness_toolbox-1.19.1-py3-none-any.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from adversarial-robustness-toolbox) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from adversarial-robustness-toolbox) (1.15.2)\r\n",
      "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.11/dist-packages (from adversarial-robustness-toolbox) (1.2.2)\r\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from adversarial-robustness-toolbox) (1.17.0)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from adversarial-robustness-toolbox) (75.2.0)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from adversarial-robustness-toolbox) (4.67.1)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.0->adversarial-robustness-toolbox) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.0->adversarial-robustness-toolbox) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.0->adversarial-robustness-toolbox) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.0->adversarial-robustness-toolbox) (2025.1.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.0->adversarial-robustness-toolbox) (2022.1.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.0->adversarial-robustness-toolbox) (2.4.1)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.2->adversarial-robustness-toolbox) (1.5.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.2->adversarial-robustness-toolbox) (3.6.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.18.0->adversarial-robustness-toolbox) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.18.0->adversarial-robustness-toolbox) (2022.1.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.18.0->adversarial-robustness-toolbox) (1.3.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.18.0->adversarial-robustness-toolbox) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.18.0->adversarial-robustness-toolbox) (2024.2.0)\r\n",
      "Downloading adversarial_robustness_toolbox-1.19.1-py3-none-any.whl (1.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: adversarial-robustness-toolbox\r\n",
      "Successfully installed adversarial-robustness-toolbox-1.19.1\r\n",
      "Robust Accuracy under FGSM attack: 0.8455021291696239\n"
     ]
    }
   ],
   "source": [
    "!pip install adversarial-robustness-toolbox\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from art.attacks.evasion import FastGradientMethod\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Convert X_test to float32 numpy array before generating adversarial examples\n",
    "X_test_float32 = X_test.astype(np.float32)\n",
    "\n",
    "classifier = PyTorchClassifier(\n",
    "    model=model,\n",
    "    loss=criterion,\n",
    "    optimizer=optimizer,\n",
    "    input_shape=(X_train.shape[1],),\n",
    "    nb_classes=2,\n",
    ")\n",
    "\n",
    "# Generate adversarial examples using float32 inputs\n",
    "fgsm = FastGradientMethod(estimator=classifier, eps=0.1)\n",
    "X_test_adv = fgsm.generate(X_test_float32)\n",
    "\n",
    "# Predict on adversarial examples\n",
    "preds = np.argmax(classifier.predict(X_test_adv), axis=1)\n",
    "\n",
    "accuracy = np.mean(preds == y_test)\n",
    "print(\"Robust Accuracy under FGSM attack:\", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 174616,
     "sourceId": 394223,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 141.429864,
   "end_time": "2025-05-21T20:14:33.171361",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-21T20:12:11.741497",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
