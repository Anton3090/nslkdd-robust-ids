{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":394223,"sourceType":"datasetVersion","datasetId":174616}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-21T18:43:03.245314Z","iopub.execute_input":"2025-05-21T18:43:03.245560Z","iopub.status.idle":"2025-05-21T18:43:03.563171Z","shell.execute_reply.started":"2025-05-21T18:43:03.245536Z","shell.execute_reply":"2025-05-21T18:43:03.562494Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/KDDTest+.arff\n/kaggle/input/KDDTest-21.arff\n/kaggle/input/KDDTest1.jpg\n/kaggle/input/KDDTrain+.txt\n/kaggle/input/KDDTrain+_20Percent.txt\n/kaggle/input/KDDTest-21.txt\n/kaggle/input/KDDTest+.txt\n/kaggle/input/KDDTrain+.arff\n/kaggle/input/index.html\n/kaggle/input/KDDTrain+_20Percent.arff\n/kaggle/input/KDDTrain1.jpg\n/kaggle/input/nsl-kdd/KDDTest+.arff\n/kaggle/input/nsl-kdd/KDDTest-21.arff\n/kaggle/input/nsl-kdd/KDDTest1.jpg\n/kaggle/input/nsl-kdd/KDDTrain+.txt\n/kaggle/input/nsl-kdd/KDDTrain+_20Percent.txt\n/kaggle/input/nsl-kdd/KDDTest-21.txt\n/kaggle/input/nsl-kdd/KDDTest+.txt\n/kaggle/input/nsl-kdd/KDDTrain+.arff\n/kaggle/input/nsl-kdd/index.html\n/kaggle/input/nsl-kdd/KDDTrain+_20Percent.arff\n/kaggle/input/nsl-kdd/KDDTrain1.jpg\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"**Dataset Import**","metadata":{}},{"cell_type":"code","source":"import kagglehub\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\n\n# Download and load the dataset\npath = kagglehub.dataset_download(\"hassan06/nslkdd\")\nprint(\"Path to dataset files:\", path)\n\n# Load train and test datasets\ntrain_df = pd.read_csv(f\"{path}/KDDTrain+.txt\", header=None)\ntest_df = pd.read_csv(f\"{path}/KDDTest+.txt\", header=None)\n\n# NSL-KDD has 41 features + 1 label column\ncolumns = [\n    'duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes',\n    'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in',\n    'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations',\n    'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login',\n    'is_guest_login', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate',\n    'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate',\n    'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count',\n    'dst_host_same_srv_rate', 'dst_host_diff_srv_rate',\n    'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate',\n    'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n    'dst_host_srv_rerror_rate', 'label', 'difficulty_level'  # added last column\n]\n\ntrain_df.columns = test_df.columns = columns\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T18:43:03.565017Z","iopub.execute_input":"2025-05-21T18:43:03.565286Z","iopub.status.idle":"2025-05-21T18:43:04.857509Z","shell.execute_reply.started":"2025-05-21T18:43:03.565268Z","shell.execute_reply":"2025-05-21T18:43:04.856808Z"}},"outputs":[{"name":"stdout","text":"Path to dataset files: /kaggle/input/\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"**Preprocessing**","metadata":{}},{"cell_type":"code","source":"# Binary classification: normal vs attack\ntrain_df['label'] = train_df['label'].apply(lambda x: 'normal' if x == 'normal' else 'attack')\ntest_df['label'] = test_df['label'].apply(lambda x: 'normal' if x == 'normal' else 'attack')\n\n# Encode categorical features\ncat_cols = ['protocol_type', 'service', 'flag']\nencoder = LabelEncoder()\nfor col in cat_cols:\n    train_df[col] = encoder.fit_transform(train_df[col])\n    test_df[col] = encoder.transform(test_df[col])\n\n# Separate features and labels\nX_train = train_df.drop('label', axis=1)\ny_train = LabelEncoder().fit_transform(train_df['label'])\n\nX_test = test_df.drop('label', axis=1)\ny_test = LabelEncoder().fit_transform(test_df['label'])\n\n# Normalize\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T18:43:04.858244Z","iopub.execute_input":"2025-05-21T18:43:04.858478Z","iopub.status.idle":"2025-05-21T18:43:05.135170Z","shell.execute_reply.started":"2025-05-21T18:43:04.858460Z","shell.execute_reply":"2025-05-21T18:43:05.134299Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"**Build & Train Deep Learning Model**","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, TensorDataset\n\n# Convert to tensors\nX_train_tensor = torch.tensor(X_train, dtype=torch.float32)\ny_train_tensor = torch.tensor(y_train, dtype=torch.long)\nX_test_tensor = torch.tensor(X_test, dtype=torch.float32)\ny_test_tensor = torch.tensor(y_test, dtype=torch.long)\n\n# DataLoader\ntrain_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=128, shuffle=True)\n\n# Define model\nclass IDSModel(nn.Module):\n    def __init__(self, input_dim):\n        super(IDSModel, self).__init__()\n        self.layers = nn.Sequential(\n            nn.Linear(input_dim, 64),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(64, 32),\n            nn.ReLU(),\n            nn.Linear(32, 2)\n        )\n    def forward(self, x):\n        return self.layers(x)\n\nmodel = IDSModel(X_train.shape[1])\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\n# Training\nfor epoch in range(10):\n    for xb, yb in train_loader:\n        out = model(xb)\n        loss = criterion(out, yb)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    print(f\"Epoch {epoch+1} - Loss: {loss.item():.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T18:43:05.136041Z","iopub.execute_input":"2025-05-21T18:43:05.136259Z","iopub.status.idle":"2025-05-21T18:43:31.759843Z","shell.execute_reply.started":"2025-05-21T18:43:05.136243Z","shell.execute_reply":"2025-05-21T18:43:31.758918Z"}},"outputs":[{"name":"stdout","text":"Epoch 1 - Loss: 0.0116\nEpoch 2 - Loss: 0.0170\nEpoch 3 - Loss: 0.0000\nEpoch 4 - Loss: 0.0001\nEpoch 5 - Loss: 0.0009\nEpoch 6 - Loss: 0.0003\nEpoch 7 - Loss: 0.0018\nEpoch 8 - Loss: 0.0009\nEpoch 9 - Loss: 0.0012\nEpoch 10 - Loss: 0.0001\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"**Evaluation**","metadata":{}},{"cell_type":"code","source":"model.eval()\nwith torch.no_grad():\n    preds = torch.argmax(model(X_test_tensor), dim=1)\n    acc = (preds == y_test_tensor).float().mean()\nprint(\"Test Accuracy:\", acc.item())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T18:43:31.760806Z","iopub.execute_input":"2025-05-21T18:43:31.761315Z","iopub.status.idle":"2025-05-21T18:43:31.778053Z","shell.execute_reply.started":"2025-05-21T18:43:31.761291Z","shell.execute_reply":"2025-05-21T18:43:31.777334Z"}},"outputs":[{"name":"stdout","text":"Test Accuracy: 0.847054660320282\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"**Real-Time Packet Detection with Scapy**","metadata":{}},{"cell_type":"code","source":"# Save model\ntorch.save(model.state_dict(), 'ids_model.pth')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T18:43:31.778854Z","iopub.execute_input":"2025-05-21T18:43:31.779099Z","iopub.status.idle":"2025-05-21T18:43:31.784556Z","shell.execute_reply.started":"2025-05-21T18:43:31.779080Z","shell.execute_reply":"2025-05-21T18:43:31.783795Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"!pip install scapy torch numpy joblib","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T18:43:31.785516Z","iopub.execute_input":"2025-05-21T18:43:31.785784Z","iopub.status.idle":"2025-05-21T18:43:34.871555Z","shell.execute_reply.started":"2025-05-21T18:43:31.785761Z","shell.execute_reply":"2025-05-21T18:43:34.870707Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: scapy in /usr/local/lib/python3.11/dist-packages (2.6.1)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.5.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy) (2024.2.0)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nimport joblib\n\n# Example: Fit scaler to your training features\nscaler = StandardScaler()\nscaler.fit(X_train)  # X_train should be your training features (without labels)\n\n# Save to a file\njoblib.dump(scaler, \"scaler.save\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T18:43:34.874272Z","iopub.execute_input":"2025-05-21T18:43:34.874518Z","iopub.status.idle":"2025-05-21T18:43:34.944081Z","shell.execute_reply.started":"2025-05-21T18:43:34.874493Z","shell.execute_reply":"2025-05-21T18:43:34.943390Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"['scaler.save']"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"from scapy.all import sniff, IP, TCP, UDP\nimport torch\nimport torch.nn as nn\nimport numpy as np\nimport joblib\nfrom datetime import datetime\n\n# Define the same model architecture\nclass IDSModel(nn.Module):\n    def __init__(self, input_dim):\n        super(IDSModel, self).__init__()\n        self.layers = nn.Sequential(\n            nn.Linear(input_dim, 64),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(64, 32),\n            nn.ReLU(),\n            nn.Linear(32, 2)\n        )\n    def forward(self, x):\n        return self.layers(x)\n\n# Load model and scaler\nmodel = IDSModel(input_dim=42)  # NSL-KDD has 42 features\nmodel.load_state_dict(torch.load(\"ids_model.pth\"))\nmodel.eval()\n\nscaler = joblib.load(\"scaler.save\")\n\n# Example feature extractor (customize to match training features)\ndef extract_features(pkt):\n    try:\n        # Very basic feature simulation\n        length = len(pkt)\n        ttl = pkt[IP].ttl if IP in pkt else 0\n        dport = pkt[TCP].dport if TCP in pkt else (pkt[UDP].dport if UDP in pkt else 0)\n        features = [length, ttl, dport]\n        features += [0] * (42 - len(features))  # Pad to 42 features\n        return np.array(features).reshape(1, -1)\n    except:\n        return np.zeros((1, 42))  # Return dummy data on failure\n\n# Packet classification and logging\ndef classify_packet(pkt):\n    features = extract_features(pkt)\n    scaled = scaler.transform(features)\n    tensor = torch.tensor(scaled, dtype=torch.float32)\n    output = model(tensor)\n    pred = torch.argmax(output).item()\n    label = \"attack\" if pred == 1 else \"normal\"\n\n    # Print & log\n    print(f\"[{datetime.now()}] Packet classified as: {label}\")\n    with open(\"log.txt\", \"a\") as f:\n        f.write(f\"{datetime.now()} | {pkt.summary()} | Result: {label}\\n\")\n\n# Start sniffing\nprint(\"Sniffing... Press Ctrl+C to stop.\")\nsniff(prn=classify_packet, count=100)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T18:43:34.944867Z","iopub.execute_input":"2025-05-21T18:43:34.945184Z","iopub.status.idle":"2025-05-21T18:43:42.667153Z","shell.execute_reply.started":"2025-05-21T18:43:34.945162Z","shell.execute_reply":"2025-05-21T18:43:42.666378Z"}},"outputs":[{"name":"stdout","text":"Sniffing... Press Ctrl+C to stop.\n[2025-05-21 18:43:35.773262] Packet classified as: normal\n[2025-05-21 18:43:35.875410] Packet classified as: normal\n[2025-05-21 18:43:35.975490] Packet classified as: normal\n[2025-05-21 18:43:36.078088] Packet classified as: normal\n[2025-05-21 18:43:36.177538] Packet classified as: normal\n[2025-05-21 18:43:36.280181] Packet classified as: normal\n[2025-05-21 18:43:36.379750] Packet classified as: normal\n[2025-05-21 18:43:36.482167] Packet classified as: normal\n[2025-05-21 18:43:36.581760] Packet classified as: normal\n[2025-05-21 18:43:36.684322] Packet classified as: normal\n[2025-05-21 18:43:36.783657] Packet classified as: normal\n[2025-05-21 18:43:36.886505] Packet classified as: normal\n[2025-05-21 18:43:36.985785] Packet classified as: normal\n[2025-05-21 18:43:37.088413] Packet classified as: normal\n[2025-05-21 18:43:37.130497] Packet classified as: normal\n[2025-05-21 18:43:37.131420] Packet classified as: normal\n[2025-05-21 18:43:37.187684] Packet classified as: normal\n[2025-05-21 18:43:37.233302] Packet classified as: normal\n[2025-05-21 18:43:37.234219] Packet classified as: attack\n[2025-05-21 18:43:37.235030] Packet classified as: normal\n[2025-05-21 18:43:37.235816] Packet classified as: attack\n[2025-05-21 18:43:37.236693] Packet classified as: normal\n[2025-05-21 18:43:37.237528] Packet classified as: normal\n[2025-05-21 18:43:37.238269] Packet classified as: normal\n[2025-05-21 18:43:37.239159] Packet classified as: normal\n[2025-05-21 18:43:37.290437] Packet classified as: normal\n[2025-05-21 18:43:37.337308] Packet classified as: normal\n[2025-05-21 18:43:37.389644] Packet classified as: normal\n[2025-05-21 18:43:37.492416] Packet classified as: normal\n[2025-05-21 18:43:37.591687] Packet classified as: normal\n[2025-05-21 18:43:37.694367] Packet classified as: normal\n[2025-05-21 18:43:37.793751] Packet classified as: normal\n[2025-05-21 18:43:37.896404] Packet classified as: normal\n[2025-05-21 18:43:37.995983] Packet classified as: normal\n[2025-05-21 18:43:38.099096] Packet classified as: normal\n[2025-05-21 18:43:38.198779] Packet classified as: normal\n[2025-05-21 18:43:38.301204] Packet classified as: normal\n[2025-05-21 18:43:38.401195] Packet classified as: normal\n[2025-05-21 18:43:38.503762] Packet classified as: normal\n[2025-05-21 18:43:38.603282] Packet classified as: normal\n[2025-05-21 18:43:38.705791] Packet classified as: normal\n[2025-05-21 18:43:38.805446] Packet classified as: normal\n[2025-05-21 18:43:38.908449] Packet classified as: normal\n[2025-05-21 18:43:39.008039] Packet classified as: normal\n[2025-05-21 18:43:39.110796] Packet classified as: normal\n[2025-05-21 18:43:39.210239] Packet classified as: normal\n[2025-05-21 18:43:39.312860] Packet classified as: normal\n[2025-05-21 18:43:39.412714] Packet classified as: normal\n[2025-05-21 18:43:39.515495] Packet classified as: normal\n[2025-05-21 18:43:39.615585] Packet classified as: normal\n[2025-05-21 18:43:39.718157] Packet classified as: normal\n[2025-05-21 18:43:39.818089] Packet classified as: normal\n[2025-05-21 18:43:39.920691] Packet classified as: normal\n[2025-05-21 18:43:40.020414] Packet classified as: normal\n[2025-05-21 18:43:40.122809] Packet classified as: normal\n[2025-05-21 18:43:40.222467] Packet classified as: normal\n[2025-05-21 18:43:40.325099] Packet classified as: normal\n[2025-05-21 18:43:40.424505] Packet classified as: normal\n[2025-05-21 18:43:40.527201] Packet classified as: normal\n[2025-05-21 18:43:40.626517] Packet classified as: normal\n[2025-05-21 18:43:40.729141] Packet classified as: normal\n[2025-05-21 18:43:40.828599] Packet classified as: normal\n[2025-05-21 18:43:40.931453] Packet classified as: normal\n[2025-05-21 18:43:41.031107] Packet classified as: normal\n[2025-05-21 18:43:41.133673] Packet classified as: normal\n[2025-05-21 18:43:41.233355] Packet classified as: normal\n[2025-05-21 18:43:41.336125] Packet classified as: normal\n[2025-05-21 18:43:41.435429] Packet classified as: normal\n[2025-05-21 18:43:41.538075] Packet classified as: normal\n[2025-05-21 18:43:41.637691] Packet classified as: normal\n[2025-05-21 18:43:41.740283] Packet classified as: normal\n[2025-05-21 18:43:41.840055] Packet classified as: normal\n[2025-05-21 18:43:41.942810] Packet classified as: normal\n[2025-05-21 18:43:42.042550] Packet classified as: normal\n[2025-05-21 18:43:42.145179] Packet classified as: normal\n[2025-05-21 18:43:42.179100] Packet classified as: normal\n[2025-05-21 18:43:42.179934] Packet classified as: normal\n[2025-05-21 18:43:42.244789] Packet classified as: normal\n[2025-05-21 18:43:42.281778] Packet classified as: normal\n[2025-05-21 18:43:42.282739] Packet classified as: attack\n[2025-05-21 18:43:42.283545] Packet classified as: normal\n[2025-05-21 18:43:42.284404] Packet classified as: attack\n[2025-05-21 18:43:42.285296] Packet classified as: attack\n[2025-05-21 18:43:42.286198] Packet classified as: attack\n[2025-05-21 18:43:42.287095] Packet classified as: attack\n[2025-05-21 18:43:42.287974] Packet classified as: attack\n[2025-05-21 18:43:42.347356] Packet classified as: normal\n[2025-05-21 18:43:42.386395] Packet classified as: normal\n[2025-05-21 18:43:42.387206] Packet classified as: attack\n[2025-05-21 18:43:42.387955] Packet classified as: normal\n[2025-05-21 18:43:42.388682] Packet classified as: normal\n[2025-05-21 18:43:42.389503] Packet classified as: normal\n[2025-05-21 18:43:42.390408] Packet classified as: normal\n[2025-05-21 18:43:42.391217] Packet classified as: normal\n[2025-05-21 18:43:42.409868] Packet classified as: attack\n[2025-05-21 18:43:42.410785] Packet classified as: attack\n[2025-05-21 18:43:42.446932] Packet classified as: normal\n[2025-05-21 18:43:42.489259] Packet classified as: normal\n[2025-05-21 18:43:42.549654] Packet classified as: normal\n[2025-05-21 18:43:42.649042] Packet classified as: normal\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"<Sniffed: TCP:98 UDP:0 ICMP:0 Other:2>"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"**Logging to a Text File**","metadata":{}},{"cell_type":"code","source":"import datetime\n\ndef log_packet(pkt, result):\n    with open(\"log.txt\", \"a\") as f:\n        f.write(f\"{datetime.datetime.now()} | {pkt.summary()} | Result: {result}\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T18:43:42.667959Z","iopub.execute_input":"2025-05-21T18:43:42.668610Z","iopub.status.idle":"2025-05-21T18:43:42.672662Z","shell.execute_reply.started":"2025-05-21T18:43:42.668590Z","shell.execute_reply":"2025-05-21T18:43:42.672058Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"**Secure Model with Adversarial Robustness Toolbox (ART)**","metadata":{}},{"cell_type":"code","source":"!pip install adversarial-robustness-toolbox\nfrom art.estimators.classification import PyTorchClassifier\nfrom art.attacks.evasion import FastGradientMethod\nimport numpy as np\nimport torch\n\n# Convert X_test to float32 numpy array before generating adversarial examples\nX_test_float32 = X_test.astype(np.float32)\n\nclassifier = PyTorchClassifier(\n    model=model,\n    loss=criterion,\n    optimizer=optimizer,\n    input_shape=(X_train.shape[1],),\n    nb_classes=2,\n)\n\n# Generate adversarial examples using float32 inputs\nfgsm = FastGradientMethod(estimator=classifier, eps=0.1)\nX_test_adv = fgsm.generate(X_test_float32)\n\n# Predict on adversarial examples\npreds = np.argmax(classifier.predict(X_test_adv), axis=1)\n\naccuracy = np.mean(preds == y_test)\nprint(\"Robust Accuracy under FGSM attack:\", accuracy)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-21T18:43:42.673508Z","iopub.execute_input":"2025-05-21T18:43:42.673771Z","iopub.status.idle":"2025-05-21T18:43:48.423376Z","shell.execute_reply.started":"2025-05-21T18:43:42.673747Z","shell.execute_reply":"2025-05-21T18:43:48.422564Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: adversarial-robustness-toolbox in /usr/local/lib/python3.11/dist-packages (1.19.1)\nRequirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from adversarial-robustness-toolbox) (1.26.4)\nRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from adversarial-robustness-toolbox) (1.15.2)\nRequirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.11/dist-packages (from adversarial-robustness-toolbox) (1.2.2)\nRequirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from adversarial-robustness-toolbox) (1.17.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from adversarial-robustness-toolbox) (75.2.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from adversarial-robustness-toolbox) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.0->adversarial-robustness-toolbox) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.0->adversarial-robustness-toolbox) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.0->adversarial-robustness-toolbox) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.0->adversarial-robustness-toolbox) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.0->adversarial-robustness-toolbox) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.18.0->adversarial-robustness-toolbox) (2.4.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.2->adversarial-robustness-toolbox) (1.5.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.2->adversarial-robustness-toolbox) (3.6.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.18.0->adversarial-robustness-toolbox) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.18.0->adversarial-robustness-toolbox) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.18.0->adversarial-robustness-toolbox) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.18.0->adversarial-robustness-toolbox) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.18.0->adversarial-robustness-toolbox) (2024.2.0)\nRobust Accuracy under FGSM attack: 0.825319375443577\n","output_type":"stream"}],"execution_count":11}]}